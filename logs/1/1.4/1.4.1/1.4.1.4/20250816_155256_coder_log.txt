
=== Coder Agent Log ===
Timestamp: 2025-08-16T15:52:56.610128
Task: Implement logic to calculate and aggregate a complexity metric (e.g., cyclomatic complexity) across history

Output:
def aggregate_complexity_over_time(commits_data):
    """
    Aggregates a complexity metric over time from historical data.

    This function processes a list of dictionaries, each representing a
    historical snapshot (e.g., a commit) with a pre-calculated complexity
    score. It calculates the average complexity for each unique date.

    Args:
        commits_data (list[dict]): A list of dictionaries, where each
                                   dictionary represents a snapshot. Expected
                                   keys are 'date' and 'complexity'.

    Returns:
        dict: A dictionary where keys are dates and values are the float
              average of the complexity metric for all entries on that date.
              Example: {'2023-10-27': 15.5, '2023-10-28': 12.0}
    """
    daily_complexities = {}

    for commit in commits_data:
        date = commit.get('date')
        complexity = commit.get('complexity')

        # Skip entries with missing date or complexity score
        if not date or complexity is None:
            continue

        if date not in daily_complexities:
            daily_complexities[date] = []

        daily_complexities[date].append(complexity)

    # Calculate the average complexity for each date from the collected lists
    aggregated_metrics = {}
    for date, complexities in daily_complexities.items():
        if complexities:  # Avoid division by zero for an empty list
            average_complexity = sum(complexities) / len(complexities)
            aggregated_metrics[date] = average_complexity

    return aggregated_metrics

==================================================
