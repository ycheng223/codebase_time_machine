
=== IntegrationTester Agent Log ===
Timestamp: 2025-08-16T15:52:20.005917
Task: Integration test for: Data Storage and Querying (RAG System)

Output:
import unittest
import os
import shutil
from typing import List, Dict, Any, Union

# --- Prerequisite Implementations (based on provided snippets) ---

# Implementation from: 1.3.2/1.3.2.2 & 1.3.2/1.3.2.3
from pydantic import BaseModel, Field

class Document(BaseModel):
    """Data model for a document to be stored and retrieved."""
    id: str = Field(..., description="Unique identifier for the document.")
    content: str = Field(..., description="The main text content of the document.")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="A dictionary for storing metadata.")

# Implementation from: 1.3.1/1.3.1.2
from sentence_transformers import SentenceTransformer
import numpy as np

class EmbeddingGenerator:
    """Generates sentence embeddings using SentenceTransformer models."""
    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):
        """
        Initializes the EmbeddingGenerator with a specified model.
        Args:
            model_name: The name of the SentenceTransformer model to use.
        """
        self.model = SentenceTransformer(model_name)

    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generates embeddings for a list of texts.
        Args:
            texts: A list of strings to be embedded.
        Returns:
            A list of embeddings, where each embedding is a list of floats.
        """
        if not texts or not isinstance(texts, list):
            return []
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        return [embedding.tolist() for embedding in embeddings]

# Implementation from: 1.3.1/1.3.1.3
import chromadb

class ChromaDBVectorStore:
    """A vector store using ChromaDB for storing and querying document embeddings."""
    def __init__(self, embedding_generator: EmbeddingGenerator, collection_name: str, db_path: str = "./chroma_test_db"):
        self.embedding_generator = embedding_generator
        self._client = chromadb.PersistentClient(path=db_path)
        self.collection_name = collection_name
        
        # Ensure a clean slate for the test collection
        try:
            self._client.delete_collection(name=self.collection_name)
        except ValueError:
            # Collection didn't exist, which is fine
            pass
        finally:
            self._collection = self._client.create_collection(name=self.collection_name)

    def add_documents(self, documents: List[Document]):
        """
        Adds a list of documents to the ChromaDB collection.
        This involves generating embeddings for the document contents.
        """
        if not documents:
            return

        contents = [doc.content for doc in documents]
        ids = [doc.id for doc in documents]
        metadatas = [doc.metadata for doc in documents]

        # Integration point: calls the embedding generator
        embeddings = self.embedding_generator.generate_embeddings(contents)

        if not embeddings:
            return

        self._collection.add(
            ids=ids,
            embeddings=embeddings,
            documents=contents,
            metadatas=metadatas
        )

    def query(self, query_text: str, top_k: int = 3) -> List[Document]:
        """
        Queries the vector store for the most similar documents to a given text.
        """
        if not query_text:
            return []

        # Integration point: calls the embedding generator
        query_embedding = self.embedding_generator.generate_embeddings([query_text])[0]

        results = self._collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )

        retrieved_docs = []
        # ChromaDB results are nested in a list because we query with a list of one embedding
        if results and results.get('ids') and results['ids'][0]:
            for i in range(len(results['ids'][0])):
                doc = Document(
                    id=results['ids'][0][i],
                    content=results['documents'][0][i],
                    metadata=results['metadatas'][0][i]
                )
                retrieved_docs.append(doc)

        return retrieved_docs

    def get_collection_size(self) -> int:
        """Helper method to get the number of items in the collection."""
        return self._collection.count()


# --- Integration Test Suite ---

class TestRAGStorageAndQueryingIntegration(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        """
        Set up class-level resources. This is run once before all tests.
        It downloads/loads the embedding model and prepares the test directory.
        """
        print("Setting up integration test suite...")
        cls.embedding_generator = EmbeddingGenerator(model_name='all-MiniLM-L6-v2')
        cls.test_db_path = "./test_rag_integration_chroma_db"
        # Ensure the test DB path is clean before starting all tests
        if os.path.exists(cls.test_db_path):
            shutil.rmtree(cls.test_db_path)
        os.makedirs(cls.test_db_path)
        print("Embedding model and test directory are ready.")

    @classmethod
    def tearDownClass(cls):
        """
        Clean up class-level resources. This is run once after all tests.
        It removes the test database directory.
        """
        if os.path.exists(cls.test_db_path):
            shutil.rmtree(cls.test_db_path)
        print("\nCleaned up test database directory. Test suite finished.")

    def setUp(self):
        """
        Set up a new, clean vector store for each individual test method.
        This ensures test isolation.
        """
        # Create a unique collection name for each test to prevent interference
        collection_name = f"test_collection_{self._testMethodName}"
        self.vector_store = ChromaDBVectorStore(
            embedding_generator=self.embedding_generator,
            collection_name=collection_name,
            db_path=self.test_db_path
        )

        # Sample documents with distinct topics for clear query results
        self.sample_docs = [
            Document(id="doc1", content="The sky is blue and vast.", metadata={"source": "nature_facts.txt", "topic": "nature"}),
            Document(id="doc2", content="An apple a day keeps the doctor away.", metadata={"source": "health_proverbs.txt", "topic": "health"}),
            Document(id="doc3", content="Python is a popular high-level programming language.", metadata={"source": "tech_intro.txt", "topic": "technology"}),
            Document(id="doc4", content="Large language models are a form of artificial intelligence.", metadata={"source": "ai_explainers.txt", "topic": "technology"})
        ]

    def test_add_and_query_for_most_relevant_document(self):
        """
        Tests the primary integration path: adding documents and retrieving the single best match for a query.
        """
        # 1. Add documents to the store. This tests the interaction where the
        #    VectorStore uses the EmbeddingGenerator to create embeddings.
        self.vector_store.add_documents(self.sample_docs)
        self.assertEqual(self.vector_store.get_collection_size(), 4, "Should have 4 documents in the store after adding.")

        # 2. Query for a specific topic. This tests the interaction where the
        #    VectorStore uses the EmbeddingGenerator to create a query embedding.
        query = "What is a common coding language?"
        results = self.vector_store.query(query, top_k=1)

        # 3. Assert the results are as expected.
        self.assertIsInstance(results, list, "Query result should be a list.")
        self.assertEqual(len(results), 1, "Should retrieve exactly one document for top_k=1.")
        
        retrieved_doc = results[0]
        self.assertIsInstance(retrieved_doc, Document, "Result item should be a Document object.")
        self.assertEqual(retrieved_doc.id, "doc3", "The most relevant document should be about Python.")
        self.assertEqual(retrieved_doc.content, "Python is a popular high-level programming language.")
        self.assertEqual(retrieved_doc.metadata["topic"], "technology")

    def test_query_for_top_k_multiple_results(self):
        """
        Tests querying for multiple relevant documents and checks if they are returned in the correct order of relevance.
        """
        # 1. Add documents.
        self.vector_store.add_documents(self.sample_docs)
        self.assertEqual(self.vector_store.get_collection_size(), 4)

        # 2. Formulate a query that is relevant to multiple documents.
        query = "Tell me about modern computer technology"
        results = self.vector_store.query(query, top_k=2)

        # 3. Assert the results.
        self.assertEqual(len(results), 2, "Should retrieve two documents for top_k=2.")

        # Check that the two most relevant documents are returned.
        retrieved_ids = {doc.id for doc in results}
        expected_ids = {"doc3", "doc4"} # Python and AI documents
        self.assertEqual(retrieved_ids, expected_ids, "Should retrieve the Python and AI documents.")

        # Check the order of relevance. The AI doc should be closer to the query.
        self.assertEqual(results[0].id, "doc4", "The AI document should be the top result.")
        self.assertEqual(results[1].id, "doc3", "The Python document should be the second result.")

    def test_query_with_no_semantically_close_documents(self):
        """
        Tests a query that is semantically distant from all stored documents.
        A vector search should still return the mathematically closest items.
        """
        # 1. Add documents.
        self.vector_store.add_documents(self.sample_docs)

        # 2. Query for a completely unrelated topic.
        query = "What are the best ingredients for a pizza?"
        results = self.vector_store.query(query, top_k=1)

        # 3. Assert the behavior.
        # Even for an unrelated query, a vector search will always return the nearest neighbor.
        # We assert that it returns *something*, as the collection is not empty.
        self.assertEqual(len(results), 1, "A query should always return a result if the collection is not empty.")
        
        # We can confirm the returned document is one of the ones we added.
        retrieved_doc_id = results[0].id
        all_doc_ids = {doc.id for doc in self.sample_docs}
        self.assertIn(retrieved_doc_id, all_doc_ids)

    def test_incremental_addition_of_documents(self):
        """
        Tests adding documents in multiple batches and confirms all are available for querying.
        """
        # 1. Add the first batch.
        self.vector_store.add_documents(self.sample_docs[:2])
        self.assertEqual(self.vector_store.get_collection_size(), 2, "Size should be 2 after first batch.")

        # 2. Add the second batch.
        self.vector_store.add_documents(self.sample_docs[2:])
        self.assertEqual(self.vector_store.get_collection_size(), 4, "Size should be 4 after second batch.")

        # 3. Verify a document from the second batch is queryable.
        results = self.vector_store.query("artificial intelligence", top_k=1)
        self.assertEqual(len(results), 1)
        self.assertEqual(results[0].id, "doc4")

        # 4. Verify a document from the first batch is still queryable.
        results_2 = self.vector_store.query("what color is the sky", top_k=1)
        self.assertEqual(len(results_2), 1)
        self.assertEqual(results_2[0].id, "doc1")
        
    def test_edge_case_empty_query_string(self):
        """
        Tests the system's behavior when an empty string is provided as a query.
        """
        self.vector_store.add_documents(self.sample_docs)
        results = self.vector_store.query("", top_k=3)
        self.assertEqual(results, [], "Querying with an empty string should return an empty list.")

    def test_edge_case_add_empty_document_list(self):
        """
        Tests that adding an empty list of documents does not change the collection or raise an error.
        """
        initial_count = self.vector_store.get_collection_size()
        self.assertEqual(initial_count, 0)
        
        # This call should be handled gracefully.
        self.vector_store.add_documents([])
        
        final_count = self.vector_store.get_collection_size()
        self.assertEqual(final_count, 0, "Adding an empty list should not change the collection size.")

if __name__ == '__main__':
    unittest.main(argv=['first-arg-is-ignored'], exit=False)

==================================================
